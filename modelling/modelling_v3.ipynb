{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighbourhood wise modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encode(X, cols):\n",
    "    # Treat new categories as a new 'unknown' category (all onehot columns are 0)\n",
    "    onehot_enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    # Fit encoder on training data\n",
    "    onehot_enc.fit(X[cols])\n",
    "    # Get the names of the new columns created\n",
    "    colnames = list(onehot_enc.get_feature_names(input_features=cols))\n",
    "    # Transform the data\n",
    "    onehot_vals = onehot_enc.transform(X[cols]).toarray()\n",
    "    # Put transformed data into dataframe\n",
    "    enc_df = pd.DataFrame(onehot_vals,columns=colnames,index=X.index)\n",
    "    # Add onehot columns back onto original dataframe and drop the original columns\n",
    "    X = pd.concat([X,enc_df],axis=1).drop(cols,axis=1)\n",
    "    return X,onehot_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the data for modelling\n",
    "df = pd.read_csv('../data/final_data_for_modelling.csv')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get a list of neighbourhoods\n",
    "neigh_list = list(df.neighbourhood.unique())\n",
    "filter_neigh_list = [neigh for neigh in neigh_list if len(df[df[\"neighbourhood\"] == neigh])>1000]\n",
    "\n",
    "filter_neigh_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make dataframe filters for each neighbourhood\n",
    "data = {}\n",
    "for neigh in filter_neigh_list:\n",
    "    df_temp = df.copy()\n",
    "    df_temp = df_temp[df_temp[\"neighbourhood\"] == neigh]\n",
    "    df_temp.drop(columns=[\"age_group\", \"neighbourhood\", \"patientid\", \"appointmentid\",\n",
    "                    \"scheduledday\", \"appointmentday\", \"showed\"] , inplace=True)\n",
    "    data[neigh] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create one model for each neighbourhood\n",
    "\n",
    "for key, datafr in data.items():\n",
    "    # Splitting dataset into test and train\n",
    "    X_train, X_test, y_train, y_test = train_test_split(datafr.drop(columns=[\"no_show\"]), datafr[\"no_show\"], random_state=0,test_size=0.2)\n",
    "\n",
    "    ## Ordinal encoder for features\n",
    "    enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "    ## Fit encoder on train and apply to test data as well\n",
    "    X_train[[\"gender\"]] = enc.fit_transform(X_train[[\"gender\"]])\n",
    "    X_test[[\"gender\"]] = enc.transform(X_test[[\"gender\"]])\n",
    "\n",
    "    ## One hot encode the train data\n",
    "    cols = [\"appointment_day_of_week\"]\n",
    "    X_train, onehot_enc = onehot_encode(X_train, cols)\n",
    "\n",
    "    # Apply onehot encoder to test data\n",
    "    colnames = columns=list(onehot_enc.get_feature_names(input_features=cols))\n",
    "    onehot_vals = onehot_enc.transform(X_test[cols]).toarray()\n",
    "\n",
    "    # Put transformed data into dataframe\n",
    "    enc_df = pd.DataFrame(onehot_vals,columns=colnames,index=X_test.index)\n",
    "    # Add onehot columns back onto original dataframe and drop the original columns\n",
    "    X_test = pd.concat([X_test,enc_df],axis=1).drop(cols, axis=1)\n",
    "\n",
    "    # Create the parameter grid based on the results of random search \n",
    "    param_grid = {\n",
    "        'max_depth' : [3,4,5,6],\n",
    "        'min_samples_leaf': [2, 3, 4, 5],\n",
    "        'n_estimators': [25, 50, 75],\n",
    "        'random_state':[0],\n",
    "        'criterion' :['gini', 'entropy'],\n",
    "        'class_weight': [{1:4}]\n",
    "    }\n",
    "\n",
    "    # Create a based model\n",
    "    rf = RandomForestClassifier()\n",
    "    # Instantiate the grid search model\n",
    "    grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                                cv = 3, n_jobs = -1, verbose = 0, scoring='precision')\n",
    "\n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    ## Train the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    ## Classsification report\n",
    "    y_pred_train = best_model.predict(X_train)\n",
    "    print(f\"Train Report: {key}\")\n",
    "    print(classification_report(y_train, y_pred_train))\n",
    "    y_pred_test = best_model.predict(X_test)\n",
    "    print(\"Test Report\")\n",
    "    print(classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('aipi520')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a98011f62da9e999c9454d2aade72bbc7f019edac84829526fe29fa43abb9ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
